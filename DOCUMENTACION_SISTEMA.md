# üõµ Rappi Analytics Agent - Documentaci√≥n T√©cnica Completa

## üìã √çndice

1. [Visi√≥n General del Sistema](#visi√≥n-general-del-sistema)
2. [Arquitectura de Contexto Completo](#arquitectura-de-contexto-completo)
3. [Implementaci√≥n RAG (Retrieval-Augmented Generation)](#implementaci√≥n-rag)
4. [Workflow de N8N y Agentes](#workflow-de-n8n-y-agentes)
5. [Sistema de Evaluaci√≥n y Feedback](#sistema-de-evaluaci√≥n-y-feedback)
6. [Interfaz de Usuario (Streamlit)](#interfaz-de-usuario-streamlit)
7. [Mejoras Futuras: M√∫ltiples Agentes en Paralelo](#mejoras-futuras)
8. [Configuraci√≥n y Despliegue](#configuraci√≥n-y-despliegue)

---

## üéØ Visi√≥n General del Sistema

El **Rappi Analytics Agent** es un sistema de inteligencia artificial que convierte preguntas en lenguaje natural sobre m√©tricas de negocio de Rappi en consultas SQL ejecutables, proporcionando respuestas contextualizadas y visualizaciones autom√°ticas.

### Objetivo Principal
Proporcionar a los equipos de Growth de Rappi una herramienta que les permita:
- Hacer preguntas en lenguaje natural sobre m√©tricas de negocio
- Obtener respuestas basadas en datos reales de la base de datos
- Visualizar autom√°ticamente los resultados
- Evaluar la calidad de las consultas generadas

### Stack Tecnol√≥gico
- **Frontend**: Streamlit (interfaz de chat)
- **Orquestaci√≥n**: N8N (workflow automation)
- **IA**: OpenAI GPT-4o-mini (generaci√≥n de SQL y respuestas)
- **Base de Datos**: PostgreSQL/Supabase (datos de m√©tricas)
- **Vector Store**: Qdrant Cloud (contexto de negocio)
- **Visualizaci√≥n**: Plotly (gr√°ficos interactivos)

---

## üß† Arquitectura de Contexto Completo

### Filosof√≠a: Contexto Completo para Mejores Resultados

El sistema implementa una arquitectura de **contexto completo** que proporciona al modelo de IA toda la informaci√≥n necesaria para generar consultas SQL precisas y relevantes. Esta aproximaci√≥n se basa en tres pilares fundamentales:

### 1. üìä Documentaci√≥n de M√©tricas de Negocio

**Ubicaci√≥n**: Vector Store (Qdrant Cloud) - Colecci√≥n `rappi_business_context`

**Contenido**:
- **13 m√©tricas principales** con definiciones detalladas
- **C√°lculos y f√≥rmulas** espec√≠ficas
- **Valores t√≠picos** y rangos esperados
- **Casos de uso** y ejemplos de aplicaci√≥n
- **Insights de negocio** y correlaciones

**M√©tricas incluidas**:
```
- Perfect Orders (0-1 scale)
- Lead Penetration (penetraci√≥n de mercado)
- Gross Profit UE (ganancia bruta por orden)
- Pro Adoption (adopci√≥n de Rappi Prime)
- Order Frequency (frecuencia de √≥rdenes)
- AOV (Average Order Value)
- Active Users (usuarios activos)
- New Users (usuarios nuevos)
- Retention Rate (tasa de retenci√≥n)
- Churn Rate (tasa de abandono)
- CAC (Customer Acquisition Cost)
- LTV (Lifetime Value)
- Revenue (ingresos)
```

**Ejemplo de documentaci√≥n**:
```markdown
Perfect Orders es una m√©trica pre-calculada (0-1 scale) que mide la calidad del servicio.

**C√°lculo**: √ìrdenes entregadas a tiempo, sin cancelaciones, sin defectos / Total √≥rdenes

**Valores**:
- 1.0 = 100% de √≥rdenes perfectas
- 0.8 = 80% de √≥rdenes perfectas
- < 0.7 = Requiere atenci√≥n inmediata

**Uso en SQL**:
```sql
SELECT zone, l0w_value as perfect_order_rate
FROM metrics_input
WHERE metric = 'Perfect Orders'
ORDER BY l0w_value DESC;
```
```

### 2. üóÑÔ∏è DDL Schemas (Esquemas de Base de Datos)

**Ubicaci√≥n**: Vector Store (Qdrant Cloud) - Colecci√≥n `rappi_business_context`

**Contenido**:
- **Estructura completa** de las tablas
- **Tipos de datos** y restricciones
- **√çndices** y optimizaciones
- **Reglas cr√≠ticas** de uso
- **Ejemplos de datos** de muestra

**Tablas documentadas**:

#### `metrics_input` (Todas las m√©tricas de negocio)
```sql
CREATE TABLE metrics_input (
    id BIGSERIAL PRIMARY KEY,
    country VARCHAR(10),        -- MX, CO, BR, CL, AR, PE, EC, CR, UY
    city VARCHAR(100),          -- Ciudad
    zone VARCHAR(200),          -- Zona
    zone_type VARCHAR(50),      -- Clasificaci√≥n de zona
    metric VARCHAR(100),        -- ‚ö†Ô∏è CR√çTICO: Nombre de m√©trica
    l0w_value NUMERIC(10,4),    -- Semana actual
    l1w_value NUMERIC(10,4),    -- 1 semana atr√°s
    l2w_value NUMERIC(10,4),    -- 2 semanas atr√°s
    -- ... hasta l8w_value (8 semanas atr√°s)
    created_at TIMESTAMP DEFAULT NOW()
);
```

#### `orders` (Solo conteos de √≥rdenes)
```sql
CREATE TABLE orders (
    id BIGSERIAL PRIMARY KEY,
    country VARCHAR(10),
    city VARCHAR(100),
    zone VARCHAR(200),
    l0w INTEGER,                -- √ìrdenes semana actual
    l1w INTEGER,                -- 1 semana atr√°s
    -- ... hasta l8w (8 semanas atr√°s)
    created_at TIMESTAMP DEFAULT NOW()
);
```

**Reglas cr√≠ticas documentadas**:
- ‚ö†Ô∏è **TODAS las m√©tricas** est√°n en `metrics_input`
- ‚ö†Ô∏è **SIEMPRE filtrar** por `metric = 'Nombre Exacto'`
- ‚ö†Ô∏è **Para tendencias** usar `l0w_value`, `l1w_value`, etc.
- ‚ö†Ô∏è **Para agregaciones** usar `AVG()`, `MIN()`, `MAX()`, `COUNT()`

### 3. üèÜ Gold Queries (Consultas Validadas)

**Ubicaci√≥n**: Vector Store (Qdrant Cloud) - Colecci√≥n `rappi_business_context`

**Contenido**:
- **Preguntas frecuentes** con sus consultas SQL correspondientes
- **Scores de calidad** (1-5 estrellas)
- **Patrones de consulta** validados
- **Ejemplos de mejores pr√°cticas**

**Ejemplos de Gold Queries**:

```sql
-- Pregunta: "Top 5 zonas con mejor Perfect Order"
SELECT zone, country, city, l0w_value as perfect_order_rate
FROM metrics_input
WHERE metric = 'Perfect Orders'
  AND l0w_value IS NOT NULL
ORDER BY l0w_value DESC
LIMIT 5;

-- Pregunta: "Compara Perfect Order entre M√©xico y Colombia"
SELECT
    country,
    AVG(l0w_value) as avg_perfect_order,
    MIN(l0w_value) as min_perfect_order,
    MAX(l0w_value) as max_perfect_order,
    COUNT(*) as num_zones
FROM metrics_input
WHERE metric = 'Perfect Orders'
  AND country IN ('MX', 'CO')
GROUP BY country
ORDER BY avg_perfect_order DESC;
```

---

## üîç Implementaci√≥n RAG (Retrieval-Augmented Generation)

### Arquitectura RAG

El sistema implementa un **RAG h√≠brido** que combina:

1. **B√∫squeda sem√°ntica** en el vector store
2. **Contexto estructurado** de m√©tricas y esquemas
3. **Ejemplos validados** de consultas SQL

### Flujo de B√∫squeda de Contexto

```mermaid
graph TD
    A[Pregunta del Usuario] --> B[Generar Embedding]
    B --> C[Buscar en Qdrant]
    C --> D[Obtener Top 5 Contextos]
    D --> E[Filtrar por Relevancia]
    E --> F[Combinar Contextos]
    F --> G[Enriquecer Prompt del Agente]
```

### Configuraci√≥n de Qdrant

**Colecci√≥n**: `rappi_business_context`
**Embeddings**: OpenAI `text-embedding-3-small` (1536 dimensiones)
**Top-K**: 5 contextos m√°s relevantes
**Filtros**: Por categor√≠a (metrics, ddl, queries)

### Categor√≠as de Contexto

```python
CONTEXT_CATEGORIES = {
    "business_metric": "Documentaci√≥n de m√©tricas de negocio",
    "ddl_schema": "Esquemas de base de datos",
    "validated_query": "Consultas SQL validadas",
    "geography": "Informaci√≥n geogr√°fica",
    "data_structure": "Estructura de datos"
}
```

### Proceso de Enriquecimiento

1. **B√∫squeda sem√°ntica**: Encuentra contextos relacionados con la pregunta
2. **Filtrado por relevancia**: Score > 0.7
3. **Combinaci√≥n inteligente**: Mezcla m√©tricas, DDL y ejemplos
4. **Formateo para prompt**: Estructura el contexto para el agente

---

## ü§ñ Workflow de N8N y Agentes

### Arquitectura del Workflow

```mermaid
graph TD
    A[Webhook] --> B[AI Agent - SQL Generator]
    B --> C[Extract SQL]
    C --> D[Execute SQL Query]
    D --> E[Evaluator Agent]
    E --> F{Should Reject?}
    F -->|Yes| G[Prepare Regeneration]
    G --> B
    F -->|No| H[Answer Generator]
    H --> I[Detect Visualization]
    I --> J[Generate Chart]
    J --> K[Compile Response]
    K --> L[Respond to Webhook]
```

### Componentes del Workflow

#### 1. **AI Agent - SQL Generator**
- **Modelo**: GPT-4o-mini
- **Temperatura**: 0.1 (consistencia)
- **Max Tokens**: 500
- **Contexto**: Vector Store + DDL + Gold Queries
- **Memoria**: PostgreSQL Chat Memory

**Prompt del Sistema**:
```
You are an expert SQL analyst for Rappi's analytics database with access to business context and query validation tools.

**YOUR TOOLS:**
1. **Vector Store Search**: Use this FIRST to find business context, metric definitions, and examples for the metrics mentioned in the question.
2. **SQL Executor**: You can test queries before returning them (optional for validation).

**WORKFLOW:**
1. First, search the vector store for business context about the metrics/KPIs mentioned
2. Generate SQL query based on schema and context found
3. Return the final SQL query

**DATABASE SCHEMA:**
[DDL completo incluido aqu√≠]

**IMPORTANT RULES:**
1. ALL metrics are in metrics_input table
2. Always filter: WHERE metric = 'Exact Metric Name'
3. Use aggregations (AVG, MIN, MAX, COUNT) when grouping
4. For comparisons, use GROUP BY country/zone
5. For trends, select l0w_value, l1w_value, l2w_value, etc.
6. Check NULL values with IS NOT NULL
```

#### 2. **Evaluator Agent**
- **Modelo**: GPT-4o-mini
- **Temperatura**: 0.2
- **Max Tokens**: 800
- **Prop√≥sito**: Evaluar calidad de la consulta SQL

**Criterios de Evaluaci√≥n**:
```json
{
  "strategic_value": "Relevancia para Growth Manager (0-10)",
  "query_correctness": "Correcci√≥n l√≥gica y estructura (0-10)",
  "efficiency_gain": "Ahorro de tiempo vs an√°lisis manual (0-10)",
  "overall_score": "Promedio de los 3 criterios",
  "should_reject": "true si overall_score < 6.5 o query_correctness < 5",
  "feedback": "Feedback consolidado con sugerencias"
}
```

#### 3. **Answer Generator Agent**
- **Modelo**: GPT-4o-mini
- **Temperatura**: 0.3
- **Max Tokens**: 400
- **Prop√≥sito**: Generar respuesta en lenguaje natural

**Formato de Respuesta**:
- 2-4 oraciones concisas
- N√∫meros clave e insights
- Implicaciones de negocio
- Lenguaje no t√©cnico

### Sistema de Iteraciones

El sistema implementa un **mecanismo de iteraci√≥n** con feedback:

1. **M√°ximo 3 iteraciones** por consulta
2. **Feedback autom√°tico** del evaluador
3. **Regeneraci√≥n** con contexto mejorado
4. **Aceptaci√≥n forzada** despu√©s de 3 intentos

---

## üìä Sistema de Evaluaci√≥n y Feedback

### Evaluaci√≥n Autom√°tica

#### Criterios de Calidad (0-10)

1. **Strategic Value** (Valor Estrat√©gico)
   - Relevancia para Growth Manager
   - Accionabilidad de los resultados
   - Potencial de adopci√≥n

2. **Query Correctness** (Correcci√≥n de Consulta)
   - Estructura l√≥gica correcta
   - Sintaxis SQL v√°lida
   - Coherencia con la pregunta

3. **Efficiency Gain** (Ganancia de Eficiencia)
   - Ahorro de tiempo vs an√°lisis manual
   - Automatizaci√≥n de tareas repetitivas
   - Reducci√≥n de errores humanos

#### Umbrales de Decisi√≥n

```python
EVALUATION_THRESHOLDS = {
    "accept": 6.5,           # Score m√≠nimo para aceptar
    "reject": 5.0,           # Score m√≠nimo de correcci√≥n
    "max_iterations": 3,     # M√°ximo de iteraciones
    "high_quality": 8.0      # Score de alta calidad
}
```

### Sistema de Feedback de Usuario

#### Componente de Feedback (Streamlit)

**Funcionalidades**:
- **Escala de 1-5 estrellas** para calificar respuestas
- **Comentarios opcionales** para feedback detallado
- **Almacenamiento autom√°tico** en vector DB para consultas de alta calidad (4+ estrellas)
- **Integraci√≥n con webhook** de N8N

#### Flujo de Feedback

```mermaid
graph TD
    A[Usuario Califica Respuesta] --> B{Score >= 4?}
    B -->|Yes| C[Almacenar en Vector DB]
    B -->|No| D[Solo Registrar Feedback]
    C --> E[Usar para Aprendizaje Futuro]
    D --> F[An√°lisis de Mejoras]
```

#### Almacenamiento de Gold Queries

Las consultas con **4+ estrellas** se almacenan autom√°ticamente como "Gold Queries" para:
- Mejorar futuras generaciones
- Crear patrones de consulta validados
- Entrenar el sistema con ejemplos de alta calidad

---

## üñ•Ô∏è Interfaz de Usuario (Streamlit)

### Caracter√≠sticas Principales

#### 1. **Chat Interactivo**
- Interfaz de chat moderna y responsive
- Historial de conversaci√≥n persistente
- Indicadores de carga y estado

#### 2. **Visualizaci√≥n Autom√°tica**
- **Detecci√≥n inteligente** del tipo de gr√°fico
- **Gr√°ficos de barras** para comparaciones
- **Gr√°ficos de l√≠nea** para tendencias
- **Gr√°ficos de pie** para distribuciones
- **Preprocesamiento** de datos complejos

#### 3. **Mostrar Datos Tabulares**
- **Tablas interactivas** con pandas
- **Filtrado y ordenamiento** autom√°tico
- **Paginaci√≥n** para grandes datasets
- **Formateo** de n√∫meros y fechas

#### 4. **Sistema de M√©tricas**
- **Scores de calidad** en tiempo real
- **Tiempo ahorrado** estimado
- **N√∫mero de iteraciones** realizadas
- **Detalles de evaluaci√≥n** expandibles

### Componentes T√©cnicos

#### Preprocesamiento de Visualizaciones

```python
def preprocess_chart_data(viz_data):
    """
    Preprocesa datos complejos donde X e Y son objetos JSON.
    Maneja casos como:
    - Objetos con m√∫ltiples m√©tricas
    - Datos anidados de zona/ciudad/pa√≠s
    - Conversi√≥n de escalas (0-1 a porcentajes)
    """
```

#### Extracci√≥n de Tablas

```python
def extract_data_table_from_chart(viz_data):
    """
    Extrae tablas de datos del JSON de visualizaci√≥n.
    Convierte objetos complejos en DataFrames de pandas.
    """
```

### Configuraci√≥n de Webhook

```python
WEBHOOK_URL = "https://sswebhookss.gaussiana.io/webhook/604b1f14-eacb-4f33-91c7-60a914831b3c"
```

---

## üöÄ Mejoras Futuras: M√∫ltiples Agentes en Paralelo

### Visi√≥n: Arquitectura de Agentes Paralelos

Bas√°ndose en el diagrama proporcionado, el sistema futuro implementar√°:

#### 1. **Clasificaci√≥n de Complejidad**
```mermaid
graph TD
    A[Pregunta del Usuario] --> B[Clasificador de Complejidad]
    B --> C[Question Complexity]
    B --> D[Schema Complexity]
    B --> E[SQL Complexity]
    B --> F[Business Context Matching]
```

#### 2. **Agentes Especializados en Paralelo**

**Agente de Consultas Simples**:
- Preguntas directas sobre m√©tricas
- Consultas de una sola tabla
- Agregaciones b√°sicas

**Agente de Consultas Complejas**:
- Joins entre m√∫ltiples tablas
- Consultas con subconsultas
- An√°lisis de tendencias complejas

**Agente de An√°lisis de Negocio**:
- Correlaciones entre m√©tricas
- Insights de crecimiento
- An√°lisis de segmentaci√≥n

**Agente de Optimizaci√≥n**:
- Consultas eficientes
- √çndices recomendados
- Mejores pr√°cticas SQL

#### 3. **Sistema de S√≠ntesis**

```mermaid
graph TD
    A[Agente 1] --> E[S√≠ntesis]
    B[Agente 2] --> E
    C[Agente 3] --> E
    D[Agente N] --> E
    E --> F[Mejor Consulta SQL]
    E --> G[Interpretaci√≥n de Pregunta]
```

#### 4. **Evaluaci√≥n Comparativa**

- **Score de cada agente** por consulta
- **Selecci√≥n del mejor resultado**
- **Aprendizaje** de patrones exitosos
- **Mejora continua** de especializaci√≥n

### Implementaci√≥n T√©cnica

#### Estructura de Agentes Paralelos

```python
class ParallelAgentSystem:
    def __init__(self):
        self.agents = {
            "simple_queries": SimpleQueryAgent(),
            "complex_queries": ComplexQueryAgent(),
            "business_analysis": BusinessAnalysisAgent(),
            "optimization": OptimizationAgent()
        }
        self.synthesizer = QuerySynthesizer()
        self.evaluator = ComparativeEvaluator()
    
    async def process_query(self, question: str):
        # Ejecutar todos los agentes en paralelo
        results = await asyncio.gather(*[
            agent.generate_sql(question) 
            for agent in self.agents.values()
        ])
        
        # Sintetizar el mejor resultado
        best_query = self.synthesizer.synthesize(results)
        
        return best_query
```

#### Ventajas de la Arquitectura Paralela

1. **Mayor Precisi√≥n**: Especializaci√≥n por tipo de consulta
2. **Redundancia**: M√∫ltiples enfoques para la misma pregunta
3. **Escalabilidad**: F√°cil agregar nuevos agentes
4. **Robustez**: Fallback autom√°tico entre agentes
5. **Aprendizaje**: Mejora continua basada en resultados

---

## ‚öôÔ∏è Configuraci√≥n y Despliegue

### Requisitos del Sistema

#### Dependencias Python
```txt
streamlit>=1.28.0
requests>=2.31.0
plotly>=5.17.0
pandas>=2.1.0
qdrant-client>=1.6.0
openai>=1.3.0
python-dotenv>=1.0.0
```

#### Servicios Externos
- **OpenAI API**: Para embeddings y generaci√≥n de texto
- **Qdrant Cloud**: Para vector store
- **PostgreSQL/Supabase**: Para base de datos de m√©tricas
- **N8N**: Para orquestaci√≥n de workflows

### Configuraci√≥n de Variables de Entorno

```env
# OpenAI Configuration
OPENAI_API_KEY=tu-openai-api-key

# Qdrant Cloud Configuration
QDRANT_URL=https://tu-cluster.qdrant.io
QDRANT_API_KEY=tu-qdrant-api-key

# Database Configuration
DATABASE_URL=postgresql://user:pass@host:port/db
# O para Supabase:
SUPABASE_URL=https://tu-proyecto.supabase.co
SUPABASE_KEY=tu-supabase-key

# N8N Webhook
WEBHOOK_URL=https://sswebhookss.gaussiana.io/webhook/tu-webhook-id
```

### Proceso de Despliegue

#### 1. **Configurar Base de Datos**
```bash
# Ejecutar schema SQL
psql -h host -U user -d database -f supabase_schema.sql
```

#### 2. **Inicializar Vector Store**
```bash
cd rag_setup
python upload_to_qdrant_cloud.py
```

#### 3. **Configurar N8N Workflow**
- Importar `Agente_rappi.json`
- Configurar credenciales de OpenAI
- Configurar conexi√≥n a base de datos
- Configurar webhook URL

#### 4. **Ejecutar Aplicaci√≥n Streamlit**
```bash
cd streamlit_app
streamlit run rappi_sql_chat.py
```

### Monitoreo y Mantenimiento

#### M√©tricas Clave
- **Tiempo de respuesta** promedio
- **Tasa de √©xito** de consultas (score > 6.5)
- **N√∫mero de iteraciones** por consulta
- **Feedback de usuarios** (1-5 estrellas)
- **Uso de contexto** del vector store

#### Alertas Recomendadas
- Tiempo de respuesta > 30 segundos
- Tasa de √©xito < 70%
- Errores de conexi√≥n a servicios externos
- Uso de API > 80% del l√≠mite

---

## üìà Conclusiones

El **Rappi Analytics Agent** representa una implementaci√≥n avanzada de RAG (Retrieval-Augmented Generation) que combina:

1. **Contexto completo** con m√©tricas, DDL y gold queries
2. **Evaluaci√≥n autom√°tica** de calidad de consultas
3. **Feedback loop** para mejora continua
4. **Visualizaci√≥n autom√°tica** de resultados
5. **Arquitectura escalable** hacia m√∫ltiples agentes paralelos

### Beneficios Clave

- **Democratizaci√≥n del acceso a datos** para equipos no t√©cnicos
- **Reducci√≥n del tiempo** de an√°lisis de horas a minutos
- **Consistencia** en la interpretaci√≥n de m√©tricas
- **Escalabilidad** para m√∫ltiples equipos y pa√≠ses
- **Aprendizaje continuo** basado en feedback

### Pr√≥ximos Pasos

1. **Implementar agentes paralelos** para mayor precisi√≥n
2. **Expandir m√©tricas** y contextos de negocio
3. **Integrar m√°s fuentes de datos** (APIs externas)
4. **Desarrollar dashboards** autom√°ticos
5. **Implementar alertas** basadas en m√©tricas

---

*Documentaci√≥n generada para Rappi Analytics Agent v1.0*
*√öltima actualizaci√≥n: Diciembre 2024*
